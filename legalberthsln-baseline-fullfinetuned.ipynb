{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\nfrom huggingface_hub import notebook_login, create_repo, upload_folder\nimport pandas as pd\nfrom datasets import Dataset\nimport torch\nimport time\nimport os\nimport json\nimport psutil\nimport numpy as np\nfrom datetime import datetime\nfrom sklearn.metrics import f1_score, accuracy_score, classification_report\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import AutoTokenizer\nimport torch.nn as nn\nfrom transformers import AutoModel\nfrom torchcrf import CRF\nimport random\nfrom collections import Counter\nfrom datasets import concatenate_datasets\nimport nltk\nfrom nltk.corpus import wordnet\n\n# Download required NLTK data\nnltk.download('wordnet', quiet=True)\nnltk.download('omw-1.4', quiet=True)\nnltk.download('punkt_tab')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T13:23:37.160207Z","iopub.execute_input":"2025-08-09T13:23:37.160685Z","iopub.status.idle":"2025-08-09T13:23:47.195452Z","shell.execute_reply.started":"2025-08-09T13:23:37.160656Z","shell.execute_reply":"2025-08-09T13:23:47.194812Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"class Config:\n    # Model hyperparameters\n    bert_model_name = 'nlpaueb/legal-bert-base-uncased'\n    lstm_hidden_size = 200\n    context_hidden_size = 200\n    max_num_sentences = 20  \n    max_length = 128\n    dropout_rate = 0.4  \n    gamma = 2.0\n    weight_decay = 1e-5  \n\n    # Training parameters\n    epochs = 8\n    batch_size = 4  \n    learning_rate = 5e-5  \n\n    # Paths and repo info\n    hf_repo_id = \"Please enter your huggingface user id here/hierarchical-legal-model-improved-augmentation\"\n    output_dir = \"./improved_hierarchical_model_augmented\"\n    save_checkpoint = \"best_model\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T13:24:04.459717Z","iopub.execute_input":"2025-08-09T13:24:04.460437Z","iopub.status.idle":"2025-08-09T13:24:04.464589Z","shell.execute_reply.started":"2025-08-09T13:24:04.460412Z","shell.execute_reply":"2025-08-09T13:24:04.463870Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Login to Hugging Face Hub\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T13:24:08.322612Z","iopub.execute_input":"2025-08-09T13:24:08.323331Z","iopub.status.idle":"2025-08-09T13:24:08.337866Z","shell.execute_reply.started":"2025-08-09T13:24:08.323306Z","shell.execute_reply":"2025-08-09T13:24:08.337111Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abb7413c246f4738a9563200315e2fb7"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import load_dataset, Dataset\nfrom huggingface_hub import notebook_login","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T13:24:15.431673Z","iopub.execute_input":"2025-08-09T13:24:15.432364Z","iopub.status.idle":"2025-08-09T13:24:15.436608Z","shell.execute_reply.started":"2025-08-09T13:24:15.432334Z","shell.execute_reply":"2025-08-09T13:24:15.435917Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Load datasets\nsplits = {\n    'train': 'data/train-00000-of-00001-bb0092e0d8549337.parquet',\n    'dev': 'data/dev-00000-of-00001-af55705c75623915.parquet',\n    'test': 'data/test-00000-of-00001-2526ab833e27e0ee.parquet'\n}\n\ntrain_df = pd.read_parquet(\"hf://datasets/opennyaiorg/InRhetoricalRoles/\" + splits[\"train\"])\ndev_df = pd.read_parquet(\"hf://datasets/opennyaiorg/InRhetoricalRoles/\" + splits[\"dev\"])\ntest_df = pd.read_parquet(\"hf://datasets/opennyaiorg/InRhetoricalRoles/\" + splits[\"test\"])\n\n# Convert to Hugging Face Datasets\ntrain_ds = Dataset.from_pandas(train_df)\ndev_ds = Dataset.from_pandas(dev_df)\ntest_ds = Dataset.from_pandas(test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T13:24:17.566115Z","iopub.execute_input":"2025-08-09T13:24:17.566866Z","iopub.status.idle":"2025-08-09T13:24:21.585288Z","shell.execute_reply.started":"2025-08-09T13:24:17.566841Z","shell.execute_reply":"2025-08-09T13:24:21.584698Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def get_synonyms(word):\n    \"\"\"Get synonyms for data augmentation\"\"\"\n    synonyms = set()\n    for syn in wordnet.synsets(word):\n        for lemma in syn.lemmas():\n            synonym = lemma.name().replace(\"_\", \" \").lower()\n            if synonym != word and len(synonym) > 1:\n                synonyms.add(synonym)\n    return list(synonyms) if synonyms else [word]\n\ndef augment_sentence(sent):\n    \"\"\"Enhanced data augmentation with synonym replacement\"\"\"\n    if len(sent.strip()) == 0:\n        return sent\n\n    words = nltk.word_tokenize(sent)\n    if len(words) < 2:\n        return sent\n\n    # Choose an augmentation technique\n    choice = random.choices([1, 2, 3, 4], weights=[0.4, 0.2, 0.3, 0.1])[0]\n\n    if choice == 1:  # Synonym replacement\n        idx = random.randint(0, len(words)-1)\n        synonyms = get_synonyms(words[idx])\n        if synonyms and len(synonyms) > 0:\n            words[idx] = random.choice(synonyms)\n    elif choice == 2 and len(words) >= 4:  # Random deletion\n        del_idx = random.randint(0, len(words)-1)\n        del words[del_idx]\n    elif choice == 3 and len(words) >= 3:  # Word swap\n        i, j = random.sample(range(len(words)), 2)\n        words[i], words[j] = words[j], words[i]\n    elif choice == 4:  # Random insertion\n        idx = random.randint(0, len(words)-1)\n        synonyms = get_synonyms(words[idx])\n        if synonyms and len(synonyms) > 0:\n            words.insert(idx, random.choice(synonyms))\n\n    return \" \".join(words)\n\ndef prepare_hierarchical_datasets(train_ds, dev_ds, test_ds):\n    \"\"\"Optimized dataset preparation with efficient sampling\"\"\"\n    print(\"Preprocessing datasets with efficient sampling...\")\n\n    def get_spans_and_labels(example):\n        spans = []\n        labels = []\n        if example.get('annotations') and len(example['annotations']) > 0:\n            if example['annotations'][0].get('result'):\n                for ann in example['annotations'][0]['result']:\n                    if ann.get('value') and ann['value'].get('text') and ann['value'].get('labels'):\n                        spans.append(ann['value']['text'])\n                        labels.append(ann['value']['labels'][0])\n        return {'spans': spans, 'labels': labels}\n\n    # Apply to all splits\n    train_ds = train_ds.map(get_spans_and_labels)\n    dev_ds = dev_ds.map(get_spans_and_labels)\n    test_ds = test_ds.map(get_spans_and_labels)\n\n    # Filter out empty examples\n    train_ds = train_ds.filter(lambda x: len(x['spans']) > 0)\n    dev_ds = dev_ds.filter(lambda x: len(x['spans']) > 0)\n    test_ds = test_ds.filter(lambda x: len(x['spans']) > 0)\n\n    def prepare_for_hierarchical(example):\n        return {'text': example['spans'], 'label': example['labels']}\n\n    train_hier = train_ds.map(prepare_for_hierarchical)\n    dev_hier = dev_ds.map(prepare_for_hierarchical)\n    test_hier = test_ds.map(prepare_for_hierarchical)\n\n    # Build label mapping\n    all_labels = set()\n    for example in train_hier:\n        all_labels.update(example['label'])\n    label_list = sorted(list(all_labels))\n    label2id = {l: i for i, l in enumerate(label_list)}\n    id2label = {i: l for i, l in enumerate(label_list)}\n\n    print(f\"Identified {len(label_list)} labels: {label_list}\")\n\n    # Efficient data augmentation (only for rare classes)\n    def augment_dataset(dataset, label2id):\n        label_counts = Counter()\n        for example in dataset:\n            label_counts.update(example['label'])\n\n        # Identify rare classes\n        rare_classes = [label for label, count in label_counts.items() if count < 10]\n        print(f\"Rare classes (<10 samples): {rare_classes}\")\n\n        augmented_examples = []\n        for example in dataset:\n            labels = example['label']\n            copies = 1\n\n            if any(label in rare_classes for label in labels):\n                copies = 3  # Moderate augmentation for rare classes\n\n            # Create augmented copies\n            for _ in range(copies):\n                augmented_text = [\n                    augment_sentence(sent) if random.random() < 0.5 and sent.strip() else sent\n                    for sent in example['text']\n                ]\n                augmented_examples.append({\n                    'text': augmented_text,\n                    'label': labels.copy()\n                })\n\n        print(f\"Added {len(augmented_examples)} augmented examples\")\n        return concatenate_datasets([dataset, Dataset.from_list(augmented_examples)])\n\n    # Apply augmentation to training set\n    train_hier = augment_dataset(train_hier, label2id)\n\n    # Efficient class balancing\n    label_counts = Counter()\n    for example in train_hier:\n        label_counts.update(example['label'])\n\n    # Calculate target counts - cap at 1000 samples per class\n    max_count = min(1000, max(label_counts.values()))\n    balanced_examples = []\n    for label in label_list:\n        # Collect examples containing this label\n        class_examples = [ex for ex in train_hier if label in ex['label']]\n        current_count = label_counts[label]\n\n        # Calculate how many to add\n        needed = max(0, max_count - current_count)\n\n        # If we need to add examples, duplicate existing ones\n        if needed > 0 and class_examples:\n            # Add existing examples\n            balanced_examples.extend(class_examples)\n            # Add duplicated examples\n            duplicates = min(needed, len(class_examples))\n            balanced_examples.extend(random.choices(class_examples, k=duplicates))\n        else:\n            balanced_examples.extend(class_examples)\n\n    # Create balanced dataset\n    train_hier = Dataset.from_list(balanced_examples)\n    print(f\"Created balanced dataset with {len(train_hier)} examples\")\n\n    return train_hier, dev_hier, test_hier, label2id, id2label, label_list\n\nclass PositionalEncoding(nn.Module):\n    \"\"\"Positional embeddings for sentence order\"\"\"\n    def __init__(self, d_model, max_len=Config.max_num_sentences):\n        super().__init__()\n        self.position_emb = nn.Embedding(max_len, d_model)\n\n    def forward(self, x):\n        positions = torch.arange(x.size(1), device=x.device).unsqueeze(0)\n        return x + self.position_emb(positions)\n\nclass TransformerContextLayer(nn.Module):\n    \"\"\"Transformer-based context modeling\"\"\"\n    def __init__(self, d_model, nhead=4, dim_feedforward=512, dropout=0.1):\n        super().__init__()\n        self.encoder_layer = nn.TransformerEncoderLayer(\n            d_model=d_model,\n            nhead=nhead,\n            dim_feedforward=dim_feedforward,\n            dropout=dropout,\n            batch_first=True\n        )\n        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=1)\n\n    def forward(self, x):\n        return self.transformer_encoder(x)\n\nclass EmissionLayer(nn.Module):\n    \"\"\"Enhanced emission layer with MLP\"\"\"\n    def __init__(self, input_size, num_labels, dropout=0.2):\n        super().__init__()\n        self.mlp = nn.Sequential(\n            nn.Linear(input_size, input_size*2),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(input_size*2, num_labels)\n        )\n\n    def forward(self, x):\n        return self.mlp(x)\n\nclass FocalCRF(nn.Module):\n    \"\"\"CRF with focal loss for class imbalance\"\"\"\n    def __init__(self, num_tags, gamma=Config.gamma):\n        super().__init__()\n        self.crf = CRF(num_tags, batch_first=True)\n        self.gamma = gamma\n\n    def forward(self, emissions, tags, mask, class_weights=None):\n        # Compute standard CRF loss\n        log_likelihood = self.crf(emissions, tags, mask=mask, reduction='none')\n\n        # Apply focal loss transformation\n        pt = torch.exp(log_likelihood)\n        focal_loss = -((1 - pt) ** self.gamma) * log_likelihood\n\n        # Apply class weights if provided\n        if class_weights is not None:\n            weights_per_tag = class_weights[tags]  # (batch_size, seq_len)\n            valid_counts = mask.sum(dim=1)  # (batch_size,)\n            weights_per_sequence = weights_per_tag.sum(dim=1) / valid_counts\n            focal_loss = focal_loss * weights_per_sequence\n\n        return focal_loss.mean()\n\n    def decode(self, emissions, mask):\n        return self.crf.decode(emissions, mask=mask)\n\nclass ImprovedHSLNModel(nn.Module):\n    \"\"\"Enhanced hierarchical model with class imbalance handling\"\"\"\n    def __init__(self, num_labels, class_weights=None):\n        super().__init__()\n        self.class_weights = class_weights\n\n        # Sentence encoding\n        self.bert = AutoModel.from_pretrained(Config.bert_model_name)\n        self.sent_dropout = nn.Dropout(Config.dropout_rate)\n        self.sent_layer_norm = nn.LayerNorm(self.bert.config.hidden_size)\n\n        # Context encoding\n        self.position_enc = PositionalEncoding(self.bert.config.hidden_size)\n        self.context_encoder = TransformerContextLayer(\n            d_model=self.bert.config.hidden_size\n        )\n\n        # Emission layer\n        self.emission = EmissionLayer(\n            input_size=self.bert.config.hidden_size,\n            num_labels=num_labels\n        )\n\n        # CRF layer with focal loss\n        self.crf = FocalCRF(num_labels, gamma=Config.gamma)\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        batch_size, num_sent, seq_len = input_ids.shape\n\n        # Process each sentence\n        flat_input_ids = input_ids.view(-1, seq_len)\n        flat_mask = attention_mask.view(-1, seq_len)\n\n        bert_out = self.bert(\n            input_ids=flat_input_ids,\n            attention_mask=flat_mask\n        ).last_hidden_state\n\n        # Sentence embeddings (CLS token)\n        sent_emb = bert_out[:, 0, :]\n        sent_emb = self.sent_layer_norm(sent_emb)\n        sent_emb = self.sent_dropout(sent_emb)\n        sent_emb = sent_emb.view(batch_size, num_sent, -1)\n\n        # Context modeling\n        sent_emb = self.position_enc(sent_emb)\n        context_emb = self.context_encoder(sent_emb)\n\n        # Emissions\n        emissions = self.emission(context_emb)\n        mask = attention_mask[:, :, 0] > 0  # Sentence-level mask\n\n        if labels is not None:\n            loss = self.crf(\n                emissions,\n                labels,\n                mask=mask,\n                class_weights=self.class_weights\n            )\n            return {\"loss\": loss, \"emissions\": emissions}\n        return {\"emissions\": emissions}\n\ndef tokenize_datasets(train_hier, dev_hier, test_hier, label2id):\n    \"\"\"Tokenize datasets for hierarchical input\"\"\"\n    print(\"Tokenizing datasets...\")\n    tokenizer = AutoTokenizer.from_pretrained(Config.bert_model_name)\n\n    def tokenize_document(example):\n        sentences = example['text']\n        labels = example['label']\n        sentences = sentences[:Config.max_num_sentences]\n        labels = labels[:Config.max_num_sentences]\n        pad_len = Config.max_num_sentences - len(sentences)\n        sentences += [\"\"] * pad_len\n        labels += [list(label2id.keys())[0]] * pad_len\n\n        input_ids = []\n        attention_mask = []\n        for sent in sentences:\n            encoded = tokenizer(\n                sent,\n                padding=\"max_length\",\n                truncation=True,\n                max_length=Config.max_length,\n                return_tensors=\"pt\"\n            )\n            input_ids.append(encoded[\"input_ids\"].squeeze(0))\n            attention_mask.append(encoded[\"attention_mask\"].squeeze(0))\n\n        input_ids = torch.stack(input_ids)\n        attention_mask = torch.stack(attention_mask)\n        label_ids = torch.tensor([label2id[l] for l in labels])\n\n        return {\n            \"input_ids\": input_ids,\n            \"attention_mask\": attention_mask,\n            \"labels\": label_ids\n        }\n\n    train_tokenized = train_hier.map(tokenize_document)\n    dev_tokenized = dev_hier.map(tokenize_document)\n    test_tokenized = test_hier.map(tokenize_document)\n\n    return train_tokenized, dev_tokenized, test_tokenized, tokenizer\n\nclass HierarchicalDataset(Dataset):\n    def __init__(self, dataset):\n        self.dataset = dataset\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        item = self.dataset[idx]\n        return {\n            \"input_ids\": item[\"input_ids\"],\n            \"attention_mask\": item[\"attention_mask\"],\n            \"labels\": item[\"labels\"]\n        }\n\ndef collate_fn(batch):\n    def ensure_tensor(x):\n        return torch.tensor(x) if not isinstance(x, torch.Tensor) else x\n\n    input_ids = torch.stack([ensure_tensor(item[\"input_ids\"]) for item in batch])\n    attention_mask = torch.stack([ensure_tensor(item[\"attention_mask\"]) for item in batch])\n    labels = torch.stack([ensure_tensor(item[\"labels\"]) for item in batch])\n\n    return {\n        \"input_ids\": input_ids,\n        \"attention_mask\": attention_mask,\n        \"labels\": labels\n    }\n\ndef create_data_loaders(train_tokenized, dev_tokenized, test_tokenized):\n    train_loader = DataLoader(\n        HierarchicalDataset(train_tokenized),\n        batch_size=Config.batch_size,\n        shuffle=True,\n        collate_fn=collate_fn\n    )\n    dev_loader = DataLoader(\n        HierarchicalDataset(dev_tokenized),\n        batch_size=Config.batch_size,\n        shuffle=False,\n        collate_fn=collate_fn\n    )\n    test_loader = DataLoader(\n        HierarchicalDataset(test_tokenized),\n        batch_size=Config.batch_size,\n        shuffle=False,\n        collate_fn=collate_fn\n    )\n    return train_loader, dev_loader, test_loader\n\ndef compute_class_weights(train_hier, label2id):\n    label_counts = {label: 0 for label in label2id}\n    for example in train_hier:\n        for label in example['label']:\n            label_counts[label] += 1\n\n    total_samples = sum(label_counts.values())\n    weights = [\n        (total_samples / (label_counts[label] + 1e-5)) ** 2\n        for label in label2id\n    ]\n    weights = torch.tensor(weights, dtype=torch.float32)\n    return weights / weights.min()\n\ndef train_model(model, train_loader, dev_loader, optimizer, device, epochs, label_list):\n    \"\"\"Training loop without early stopping\"\"\"\n    print(f\"\\n{'='*30} TRAINING STARTED {'='*30}\")\n    print(f\"Training on: {device}\")\n    print(f\"Number of epochs: {epochs}\")\n    print(f\"Batch size: {Config.batch_size}\")\n    print(f\"Learning rate: {Config.learning_rate}\")\n    print(f\"Total batches: {len(train_loader)}\")\n\n    model.train()\n    best_dev_f1 = 0\n    training_start = time.time()\n    history = []\n\n    for epoch in range(epochs):\n        epoch_start = time.time()\n        total_loss = 0\n        all_preds, all_labels = [], []\n\n        # Training\n        model.train()\n        for batch_idx, batch in enumerate(train_loader):\n            optimizer.zero_grad()\n\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=labels\n            )\n\n            loss = outputs[\"loss\"]\n            loss.backward()\n\n            # Gradient clipping\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n            optimizer.step()\n\n            total_loss += loss.item()\n            emissions = outputs[\"emissions\"]\n            preds = model.crf.decode(emissions, mask=attention_mask[:, :, 0] > 0)\n\n            # Flatten predictions and labels\n            flat_labels = labels.cpu().numpy().flatten()\n            flat_preds = np.array([p for seq in preds for p in seq] +\n                                  [0]*(len(flat_labels) - sum(len(seq) for seq in preds)))\n\n            all_preds.extend(flat_preds)\n            all_labels.extend(flat_labels)\n\n            if (batch_idx + 1) % 10 == 0:\n                print(f\"Epoch {epoch+1}/{epochs} | Batch {batch_idx+1}/{len(train_loader)} | \"\n                      f\"Loss: {loss.item():.4f} | Avg Loss: {total_loss/(batch_idx+1):.4f}\")\n\n        epoch_time = time.time() - epoch_start\n        train_f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n        train_acc = accuracy_score(all_labels, all_preds)\n\n        # Validation\n        model.eval()\n        dev_metrics = evaluate_metrics(model, dev_loader, device, label_list)\n        dev_f1 = dev_metrics[\"weighted_f1\"]\n\n        history.append({\n            'epoch': epoch+1,\n            'train_loss': total_loss/len(train_loader),\n            'train_f1': train_f1,\n            'dev_f1': dev_f1\n        })\n\n        print(f\"\\nEpoch {epoch+1} completed in {epoch_time:.2f}s\")\n        print(f\"Train Loss: {total_loss/len(train_loader):.4f} | F1: {train_f1:.4f}\")\n        print(f\"Dev Weighted F1: {dev_f1:.4f} | Macro F1: {dev_metrics['macro_f1']:.4f}\")\n\n        # Save best model without early stopping\n        if dev_f1 > best_dev_f1:\n            best_dev_f1 = dev_f1\n            torch.save(model.state_dict(), os.path.join(Config.output_dir, \"best_model.pt\"))\n            print(f\"New best model saved with F1: {dev_f1:.4f}\")\n\n    training_time = time.time() - training_start\n    print(f\"Training completed in {training_time:.2f} seconds\")\n    print(f\"{'='*30} TRAINING COMPLETED {'='*30}\\n\")\n\n    # Load best model\n    model.load_state_dict(torch.load(os.path.join(Config.output_dir, \"best_model.pt\")))\n    return model, history\n\ndef evaluate_metrics(model, dataloader, device, label_list):\n    \"\"\"Comprehensive evaluation with padding masking\"\"\"\n    try:\n        model.eval()\n        all_preds, all_labels = [], []\n        total_time = 0\n        n_docs = 0\n        n_sentences = 0\n        eval_start = time.time()\n\n        with torch.no_grad():\n            for batch in dataloader:\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['labels'].to(device)\n                mask = attention_mask[:, :, 0] > 0\n\n                start = time.time()\n                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n                end = time.time()\n\n                emissions = outputs[\"emissions\"]\n                preds = model.crf.decode(emissions, mask=mask)\n\n                for i in range(len(labels)):\n                    seq_len = mask[i].sum().item()\n                    all_preds.extend(preds[i][:seq_len])\n                    all_labels.extend(labels[i][:seq_len].cpu().numpy())\n\n                total_time += (end - start)\n                n_docs += input_ids.shape[0]\n                n_sentences += mask.sum().item()\n\n        eval_end = time.time()\n        eval_time = eval_end - eval_start\n\n        labels_for_report = list(range(len(label_list)))\n        target_names = label_list\n\n        report = classification_report(\n            all_labels, all_preds,\n            labels=labels_for_report,\n            target_names=target_names,\n            output_dict=True,\n            zero_division=0\n        )\n\n        macro_f1 = report['macro avg']['f1-score']\n        weighted_f1 = report['weighted avg']['f1-score']\n        accuracy = accuracy_score(all_labels, all_preds)\n        per_label_f1 = {\n            label: report[label]['f1-score']\n            for label in label_list\n        }\n\n        latency_doc = (total_time / n_docs) * 1000 if n_docs else 0\n        latency_sent = (total_time / n_sentences) * 1000 if n_sentences else 0\n\n        return {\n            \"macro_f1\": macro_f1,\n            \"weighted_f1\": weighted_f1,\n            \"accuracy\": accuracy,\n            \"per_label_f1\": per_label_f1,\n            \"latency_ms_per_doc\": latency_doc,\n            \"latency_ms_per_sentence\": latency_sent,\n            \"eval_time_seconds\": eval_time,\n            \"num_samples\": n_docs\n        }\n\n    except Exception as e:\n        print(f\"Evaluation failed: {str(e)}\")\n        raise\n\ndef get_model_size_mb(model):\n    param_size = 0\n    for param in model.parameters():\n        param_size += param.nelement() * param.element_size()\n    buffer_size = 0\n    for buffer in model.buffers():\n        buffer_size += buffer.nelement() * buffer.element_size()\n    return (param_size + buffer_size) / (1024 ** 2)\n\ndef get_memory_footprint():\n    process = psutil.Process(os.getpid())\n    return process.memory_info().rss / (1024 ** 3)\n\ndef save_checkpoint(model, tokenizer, metrics, label2id, config, save_dir, checkpoint_name):\n    \"\"\"Save model checkpoint with all artifacts\"\"\"\n    try:\n        checkpoint_path = os.path.join(save_dir, checkpoint_name)\n        os.makedirs(checkpoint_path, exist_ok=True)\n\n        torch.save(model.state_dict(), os.path.join(checkpoint_path, \"pytorch_model.bin\"))\n        tokenizer.save_pretrained(checkpoint_path)\n\n        with open(os.path.join(checkpoint_path, \"config.json\"), \"w\") as f:\n            json.dump({\n                \"label2id\": label2id,\n                \"id2label\": {i: l for l, i in label2id.items()},\n                \"model_config\": {\n                    \"bert_model_name\": config.bert_model_name,\n                    \"lstm_hidden_size\": config.lstm_hidden_size,\n                    \"context_hidden_size\": config.context_hidden_size,\n                    \"max_num_sentences\": config.max_num_sentences,\n                    \"max_length\": config.max_length,\n                    \"dropout_rate\": config.dropout_rate,\n                    \"gamma\": config.gamma\n                }\n            }, f, indent=2)\n\n        with open(os.path.join(checkpoint_path, \"metrics.json\"), \"w\") as f:\n            json.dump(metrics, f, indent=2)\n\n        print(f\"Checkpoint saved to {checkpoint_path}\")\n        return checkpoint_path\n\n    except Exception as e:\n        print(f\"Error saving checkpoint: {str(e)}\")\n        raise\n\ndef upload_to_huggingface(save_path, repo_id):\n    \"\"\"Upload model to Hugging Face Hub\"\"\"\n    try:\n        create_repo(repo_id, exist_ok=True, token=True)\n        upload_folder(\n            repo_id=repo_id,\n            folder_path=save_path,\n            commit_message=\"Improved Hierarchical Legal Model with Enhanced Augmentation\",\n            repo_type=\"model\",\n            token=True\n        )\n        print(f\"Model uploaded to https://huggingface.co/{repo_id}\")\n    except Exception as e:\n        print(f\"Upload failed: {str(e)}\")\n\ndef main():\n    \"\"\"End-to-end training pipeline\"\"\"\n    try:\n        start_time = time.time()\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        print(f\"\\n{'='*50}\")\n        print(f\"STARTING IMPROVED HIERARCHICAL LEGAL MODEL TRAINING WITH ENHANCED AUGMENTATION\")\n        print(f\"Timestamp: {datetime.now().isoformat()}\")\n        print(f\"Device: {device}\")\n        print(f\"{'='*50}\\n\")\n\n        os.makedirs(Config.output_dir, exist_ok=True)\n\n        train_hier, dev_hier, test_hier, label2id, id2label, label_list = prepare_hierarchical_datasets(\n            train_ds, dev_ds, test_ds\n        )\n\n        class_weights = compute_class_weights(train_hier, label2id).to(device)\n        print(f\"Class weights: {class_weights.cpu().numpy()}\")\n\n        train_tokenized, dev_tokenized, test_tokenized, tokenizer = tokenize_datasets(\n            train_hier, dev_hier, test_hier, label2id\n        )\n        train_loader, dev_loader, test_loader = create_data_loaders(\n            train_tokenized, dev_tokenized, test_tokenized\n        )\n\n        model = ImprovedHSLNModel(\n            num_labels=len(label2id),\n            class_weights=class_weights\n        ).to(device)\n\n        optimizer = torch.optim.AdamW(\n            model.parameters(),\n            lr=Config.learning_rate,\n            weight_decay=Config.weight_decay\n        )\n\n        model, history = train_model(\n            model, train_loader, dev_loader,\n            optimizer, device, Config.epochs, label_list\n        )\n\n        print(\"\\nEvaluating on training set...\")\n        train_metrics = evaluate_metrics(model, train_loader, device, label_list)\n\n        print(\"\\nEvaluating on dev set...\")\n        dev_metrics = evaluate_metrics(model, dev_loader, device, label_list)\n\n        metrics = {\n            \"train\": train_metrics,\n            \"dev\": dev_metrics,\n            \"overfitting_gap\": train_metrics[\"weighted_f1\"] - dev_metrics[\"weighted_f1\"],\n            \"model_size_mb\": get_model_size_mb(model),\n            \"training_memory_footprint_gb\": get_memory_footprint(),\n            \"label2id\": label2id,\n            \"id2label\": id2label,\n            \"training_time\": time.time() - start_time,\n            \"training_history\": history\n        }\n\n        checkpoint_path = save_checkpoint(\n            model, tokenizer, metrics, label2id, Config,\n            Config.output_dir, Config.save_checkpoint\n        )\n        upload_to_huggingface(checkpoint_path, Config.hf_repo_id)\n\n        print(\"\\n==== FINAL METRICS ====\")\n        print(f\"Train Weighted F1: {train_metrics['weighted_f1']:.4f}\")\n        print(f\"Dev Weighted F1:   {dev_metrics['weighted_f1']:.4f}\")\n        print(f\"Overfitting Gap:   {metrics['overfitting_gap']:.4f}\")\n        print(f\"Model Size:        {metrics['model_size_mb']:.2f} MB\")\n        print(f\"Training Time:     {metrics['training_time']:.2f} seconds\")\n        print(f\"Saved to:          {checkpoint_path}\")\n\n        print(\"\\nPer-class F1 Scores (Dev Set):\")\n        for label, score in dev_metrics[\"per_label_f1\"].items():\n            print(f\"{label}: {score:.4f}\")\n\n        print(f\"\\n{'='*50}\")\n        print(\"TRAINING PIPELINE COMPLETED SUCCESSFULLY\")\n        print(f\"{'='*50}\")\n\n        return metrics\n\n    except Exception as e:\n        print(f\"\\n{'!'*50}\")\n        print(\"PIPELINE FAILED!\")\n        print(f\"Error: {str(e)}\")\n        with open(os.path.join(Config.output_dir, \"error_log.txt\"), \"w\") as f:\n            f.write(f\"Pipeline error at {datetime.now()}\\n\")\n            f.write(str(e))\n        return None\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T13:24:26.894741Z","iopub.execute_input":"2025-08-09T13:24:26.895363Z","iopub.status.idle":"2025-08-09T13:30:06.032850Z","shell.execute_reply.started":"2025-08-09T13:24:26.895338Z","shell.execute_reply":"2025-08-09T13:30:06.032035Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nSTARTING IMPROVED HIERARCHICAL LEGAL MODEL TRAINING WITH ENHANCED AUGMENTATION\nTimestamp: 2025-08-09T13:24:27.003638\nDevice: cuda\n==================================================\n\nPreprocessing datasets with efficient sampling...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/247 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"296b089fc4c94c63ae8bf5dfd10a5f37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/30 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c62f04fd6bcc4c42ae76a185a797d806"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53aa6e1c708b4484b8d4942d54ac52d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/247 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05509e96e79448eba8a8fc286db05f21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/30 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72ce6f61d10e4a62a39eb5a47ef820dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3a9ac83017647b18e45a7d0058a1644"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/245 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a58a48d3cf4473fb3c558780006c129"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/30 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bf844e5f64e4e56a01a555402efb468"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c51b0b1fb91741cc96be1b2c6a9c086b"}},"metadata":{}},{"name":"stdout","text":"Identified 13 labels: ['ANALYSIS', 'ARG_PETITIONER', 'ARG_RESPONDENT', 'FAC', 'ISSUE', 'NONE', 'PREAMBLE', 'PRE_NOT_RELIED', 'PRE_RELIED', 'RATIO', 'RLC', 'RPC', 'STA']\nRare classes (<10 samples): []\nAdded 245 augmented examples\nCreated balanced dataset with 4810 examples\nClass weights: [1.0000000e+00 6.2556118e+01 2.0131274e+02 3.6775160e+00 8.2221692e+02\n 5.6733036e+01 6.5607371e+00 3.0194233e+03 4.4635117e+01 2.5052148e+02\n 1.9432652e+02 1.0293336e+02 4.2040167e+02]\nTokenizing datasets...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fa3f93d7c9846459e74fad4711bf814"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f49250abcf64507b9c467f254c15472"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdc3e76a8adb47179349ea2bc8eac758"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0843e5e5b8a9490cae89b23a35193c53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4810 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f962545f6134a2aa982659b315dc013"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/30 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ed2db30337945a1af9546a16d376756"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ba2249dc8e040129e288fd2de6672cf"}},"metadata":{}},{"name":"stderr","text":"2025-08-09 13:29:50.154516: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754746190.402999      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754746190.480687      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa7a92d7aba34161b81891eb245ddde0"}},"metadata":{}},{"name":"stdout","text":"\n============================== TRAINING STARTED ==============================\nTraining on: cuda\nNumber of epochs: 8\nBatch size: 4\nLearning rate: 5e-05\nTotal batches: 1203\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61b2d70376dd490b88f737fe0830e774"}},"metadata":{}},{"name":"stdout","text":"\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\nPIPELINE FAILED!\nError: CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 171.12 MiB is free. Process 3999 has 15.72 GiB memory in use. Of the allocated memory 15.39 GiB is allocated by PyTorch, and 44.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"}],"execution_count":13}]}